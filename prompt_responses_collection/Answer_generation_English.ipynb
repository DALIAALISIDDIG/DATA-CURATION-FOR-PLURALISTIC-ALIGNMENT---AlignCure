{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hL10qg8_6Hxs"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqcVp8WsMeW4"
      },
      "outputs": [],
      "source": [
        "!pip install optimum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuCBcRdjMtW5"
      },
      "outputs": [],
      "source": [
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  # Use cu117 if on CUDA 11.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G5KPMYTLJvg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import io\n",
        "from google.colab import files\n",
        "import optimum\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from ast import Str\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "access_token = userdata.get('HF_TOKEN')\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WySWyzrnVVlZ"
      },
      "source": [
        "### Load csv files\n",
        "- Bad prompts contains no context and negative context\n",
        "- Good prompts contains positive context\n",
        "- Files can be found here:\n",
        "https://drive.google.com/drive/folders/17wfyv9uhyxjTbbcTXKscjsXAKfDiHkoO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aG2SkMqVigT"
      },
      "outputs": [],
      "source": [
        "df_gender_bad_prompts = pd.read_csv(\".../gender_bad_prompts.csv\", sep = \";\")\n",
        "df_gender_bad_prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3MknwXbPaxv"
      },
      "outputs": [],
      "source": [
        "df_gender_good_prompts = pd.read_csv(\".../gender_good_prompts.csv\", sep = \";\")\n",
        "df_gender_good_prompts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVbtqQUVHFNd"
      },
      "source": [
        "## Load LLM: Wizard-Vicuna-7B-Uncensored-GPTQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUT-K0YcJpIA"
      },
      "outputs": [],
      "source": [
        "model_wizard_name = \"TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ\"\n",
        "\n",
        "model_wizard = AutoModelForCausalLM.from_pretrained(model_wizard_name, device_map=\"auto\", use_auth_token=access_token)\n",
        "tokenizer_wizard = AutoTokenizer.from_pretrained(model_wizard_name, use_auth_token=access_token, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTVVWc9TKJRd"
      },
      "outputs": [],
      "source": [
        "def get_answer_wizard(row) -> Str:\n",
        "    if type(row[\"context\"]) == float:\n",
        "      prompt = row[\"question\"]\n",
        "    else:\n",
        "      prompt = row[\"context\"] + \" \" + row[\"question\"]\n",
        "\n",
        "    model_inputs = tokenizer_wizard(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    model_inputs = {key: tensor.to(model_wizard.device) for key, tensor in model_inputs.items()}\n",
        "\n",
        "    output = model_wizard.generate(**model_inputs,\n",
        "                            do_sample=True,\n",
        "                            pad_token_id=tokenizer_wizard.eos_token_id,\n",
        "                            min_new_tokens=50,\n",
        "                            max_new_tokens=200,\n",
        "                            temperature=0.7,\n",
        "                            top_k=50,\n",
        "                            top_p=0.95,\n",
        "                            num_return_sequences=1)\n",
        "\n",
        "    answer = tokenizer_wizard.decode(output[0], skip_special_tokens=True)\n",
        "    return answer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used function to generate answers in parts as it took too long otw."
      ],
      "metadata": {
        "id": "AAA7EDmkfldo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE4JQx5NKi-3"
      },
      "outputs": [],
      "source": [
        "start = 0\n",
        "end = 5000\n",
        "diff = end - start\n",
        "prompt_df = df_gender_bad_prompts.iloc[start:end,:].reset_index(drop=True)\n",
        "step = 100\n",
        "for index in tqdm(range(0, diff, step)):\n",
        "  prompt_df.loc[index:index+step-1,\"answer\"] = prompt_df.iloc[index:index+step,:].progress_apply(get_answer_wizard, axis = 1)\n",
        "  prompt_df.to_csv(\".../Answers_bad_prompts/llm_wizard_responses_{}_{}.csv\".format(start,end), index = False, sep = \";\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answers are stored here: https://drive.google.com/drive/folders/1GK8_921YhJmuGLQOBT_82nklEen22YV0?usp=drive_link"
      ],
      "metadata": {
        "id": "-eDR33jNgsOF"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}